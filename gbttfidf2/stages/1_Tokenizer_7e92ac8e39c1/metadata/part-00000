{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1702023105158,"sparkVersion":"3.5.0","uid":"Tokenizer_7e92ac8e39c1","paramMap":{"outputCol":"words","inputCol":"text"},"defaultParamMap":{"outputCol":"Tokenizer_7e92ac8e39c1__output"}}
